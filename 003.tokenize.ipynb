{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# issue\n",
    "* 사용자사전을 위해 ckonlpy 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T06:16:40.957446Z",
     "start_time": "2021-01-13T06:16:40.119204Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\jpype\\_core.py:217: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python36\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container {width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm,tqdm_notebook  # 진행과정 시각화\n",
    "tqdm.pandas() #apply사용\n",
    "from datetime import timedelta  # 시간날짜\n",
    "\n",
    "import re\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import math \n",
    "\n",
    "import konlpy\n",
    "from konlpy.tag import Komoran,Okt,Kkma,Twitter  # 자연어처리\n",
    "okt = Okt(max_heap_size=5120)\n",
    "\n",
    "import ckonlpy\n",
    "tw = ckonlpy.tag.Twitter()\n",
    "new_noun = pd.read_excel('단어사전.xlsx')['단어'].to_list()\n",
    "tw.add_dictionary(new_noun,'Noun')\n",
    "\n",
    "#한글깨짐방지\n",
    "plt.rc('font',family='Malgun Gothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML('<style>.container {width:100% !important; }</style>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T06:16:40.968449Z",
     "start_time": "2021-01-13T06:16:40.958447Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def tokenized(path, dataframe, keyword, stopword, batch_size = 10000):\n",
    "    '''크롤링된 데이터를 불러와 ckonlpy로 토크나이즈 진행\n",
    "    사용자정의사전을 쉽게 등록할 수 있어 ckonlpy를 사용하여 진행\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    path(string) : 저장경로\n",
    "    dataframe(DataFrame) : 분석할 df\n",
    "    keyword(string) : sw에 추가하기 위함\n",
    "    stopword(list) : 불용어 리스트\n",
    "    batch_size : 한번에 진행할 row수 (과도하게 늘리면 Java heap memory오류 발생)\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    DataFrame 형태로 './output/token/{keyword}_{start}~{end}.csv' 형태로 저장\n",
    "    post_dates   year   month  title  text     url    Noun        Adjective\n",
    "    2011-02-31   2011   02     제목   [전체내용]    url    [명사군]    [형용사군]\n",
    "\n",
    "    '''\n",
    "    #저장 위치 \n",
    "    os.makedirs(f'./{path}/token/{keyword}',exist_ok=True)\n",
    "    # stopword에 검색어 추가\n",
    "    stopword.append(keyword.split(' ')[0])\n",
    "    \n",
    "    start = 0\n",
    "    end = len(dataframe)\n",
    "    \n",
    "    print(keyword)\n",
    "    if end<=batch_size:    \n",
    "        # tqdm.pandas(desc = '토큰화')\n",
    "        token_df = dataframe.iloc[start:end]['full_text'].progress_apply(lambda x: tw.pos(x, norm=True, stem=True))\n",
    "        \n",
    "        token_df_e = token_df.explode()\n",
    "        # tqdm.pandas(desc = '단어추출')\n",
    "        token_noun = token_df_e.apply(lambda x: x[0] if x[1] == 'Noun' else np.nan).dropna()\n",
    "        token_adj = token_df_e.apply(lambda x: x[0] if x[1] == 'Adjective' else np.nan).dropna()\n",
    "\n",
    "        # 클리닝\n",
    "        # tqdm.pandas(desc = '클리닝')\n",
    "        token_noun = token_noun[token_noun.apply(lambda word: (len(word) > 1) & (word not in sw))]\n",
    "        token_adj = token_adj[token_adj.apply(lambda word: (len(word) > 1) & (word not in sw))]\n",
    "        \n",
    "        #저장\n",
    "        main_df = pd.merge(dataframe, token_noun.groupby(level=0).agg(list).rename(\n",
    "            'Noun'), how='left', left_index=True, right_index=True)\n",
    "        main_df = pd.merge(main_df, token_adj.groupby(level=0).agg(list).rename(\n",
    "            'Adjective'), how='left', left_index=True, right_index=True)\n",
    "        main_df.to_csv(f'./{path}/token/{keyword}_{start}~{end}.csv')\n",
    "        \n",
    "    else : #10000개 이상인경우 분할 작업\n",
    "        final_end = len(dataframe)\n",
    "        epoch = math.ceil(final_end/batch_size)\n",
    "        start = 0\n",
    "        end = batch_size\n",
    "        while epoch != 0:\n",
    "            # tqdm.pandas(desc = '토큰화')\n",
    "            token_df = dataframe.iloc[start:end]['full_text'].progress_apply(lambda x: tw.pos(x, norm=True, stem=True))\n",
    "            token_df_e = token_df.explode()\n",
    "            # tqdm.pandas(desc = '단어추출')\n",
    "            token_noun = token_df_e.apply(lambda x: x[0] if x[1] == 'Noun' else np.nan).dropna()\n",
    "            token_adj = token_df_e.apply(lambda x: x[0] if x[1] == 'Adjective' else np.nan).dropna()\n",
    "\n",
    "            # 클리닝\n",
    "            # tqdm.pandas(desc = '클리닝')\n",
    "            token_noun = token_noun[token_noun.apply(lambda word: (len(word) > 1) & (word not in sw))]\n",
    "            token_adj = token_adj[token_adj.apply(lambda word: (len(word) > 1) & (word not in sw))]\n",
    "\n",
    "            #저장\n",
    "            main_df = pd.merge(dataframe.iloc[start:end], token_noun.groupby(level=0).agg(list).rename(\n",
    "                'Noun'), how='left', left_index=True, right_index=True)\n",
    "            main_df = pd.merge(main_df, token_adj.groupby(level=0).agg(list).rename(\n",
    "                'Adjective'), how='left', left_index=True, right_index=True)\n",
    "#             os.makedirs(f'./new_output/token/{keyword}',exist_ok=True)\n",
    "            main_df.to_csv(f'./{path}/token/{keyword}/{keyword}_{start}~{end}.csv')\n",
    "                   \n",
    "            #next turn\n",
    "            if epoch >2 :\n",
    "                start += batch_size\n",
    "                end += batch_size\n",
    "            else :      \n",
    "                start += batch_size\n",
    "                end = final_end\n",
    "            \n",
    "            epoch -= 1\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### heap 메모리 부족 오류 발생\n",
    "* heap메모리를 4GB부여하고, 15000개 단위로 분할하여 작업진행 (2만은 가끔 메모리터짐)\n",
    "* 저장시 기본사항을 붙일수 있게 작업\n",
    "* 진행이 길어질수록 속도감소(메모리문제로 추정)하기 때문에 재실행필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T07:02:00.632694Z",
     "start_time": "2021-01-13T06:16:40.969449Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0018ccc9d54d779cfddb7b3247d95c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                        | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "강릉\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:28<00:00, 47.86it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 10000/10000 [04:19<00:00, 38.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 10000/10000 [05:06<00:00, 32.67it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 10000/10000 [05:15<00:00, 31.66it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 10000/10000 [07:15<00:00, 22.96it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 10000/10000 [08:40<00:00, 19.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 10000/10000 [06:55<00:00, 24.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4164/4164 [03:01<00:00, 22.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#임시 속초/속초해수욕장\n",
    "sw = list(pd.read_excel(\"stopword(cp949).xlsx\",encoding = 'cp949')['불용어']) #불용어 불러오기\n",
    "path = 'new_output'\n",
    "folder_path = f'./{path}/크롤링_통합/'\n",
    "file_list = os.listdir(folder_path)\n",
    "for file in tqdm_notebook(file_list[:31]):\n",
    "    file_name = file.split('.')[0]\n",
    "    main_df = pd.read_csv(folder_path + file)\n",
    "    keyword = file.split('_')[0]\n",
    "    tokenized(path, main_df, keyword, sw)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T07:02:00.639695Z",
     "start_time": "2021-01-13T07:02:00.636694Z"
    }
   },
   "outputs": [],
   "source": [
    "# file = '광진 +양양_통합_5044.csv'\n",
    "# file_name = file.split('.')[0]\n",
    "# main_df = pd.read_csv(path + file)\n",
    "# keyword = file.split('_')[0]\n",
    "# tokenized(main_df,file_name,keyword,sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T07:02:00.646698Z",
     "start_time": "2021-01-13T07:02:00.641695Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['강릉_통합_74164.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
