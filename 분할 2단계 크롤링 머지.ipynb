{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T05:02:59.396582Z",
     "start_time": "2020-06-15T05:02:58.767438Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T05:02:59.421587Z",
     "start_time": "2020-06-15T05:02:59.397582Z"
    }
   },
   "outputs": [],
   "source": [
    "filter_word = pd.read_excel('filter_word.xlsx')['filter_word'].values\n",
    "path = './output/크롤링/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T05:05:56.749346Z",
     "start_time": "2020-06-15T05:02:59.741660Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def crawling_merge(path, verbose=True, not_all=False, sep_list=''):\n",
    "    '''크롤링된 keyword별 폴더가 위치한 경로를 입력하면, 각 폴더에 있는 csv파일을 통합하고 통합폴더에 저장한다.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path(string) : 크롤링 결과폴더 경로\n",
    "    verbose(bool) : default = True, 각 폴더 통합진행과정 출력\n",
    "    not_all(bool) : default = False, 전체폴더가 아닌 일부 사용시\n",
    "    sep_list(list) : default = '', 일부폴더 지정\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    result_df : DataFrame\n",
    "        각 keyword별 전후차이 비교\n",
    "    통합폴더에 각 keyword별로 저장 ex) f\"{키워드}_통합_{전체 row수}.csv\"\n",
    "    \n",
    "    '''\n",
    "    result_dict = dict()\n",
    "    result_dict['keyword'] = []\n",
    "    result_dict['before_len'] = []\n",
    "    result_dict['after_len'] = []\n",
    "    \n",
    "    \n",
    "    #각 폴더별로 자동화 \n",
    "    os.makedirs('./output/크롤링/통합',exist_ok=True)\n",
    "    folder_list = os.listdir(path)\n",
    "    folder_list.remove('통합')\n",
    "\n",
    "    #일부일 경우\n",
    "    if not_all == False:\n",
    "        folder_list = os.listdir(path)\n",
    "        folder_list.remove('통합')\n",
    "    else :      \n",
    "        folder_list = sep_list\n",
    "\n",
    "    for folder in tqdm_notebook(folder_list,desc = '전체'):\n",
    "        file_list = os.listdir(path+folder)\n",
    "        file_path = path+folder+'/'\n",
    "        all_df = pd.DataFrame()\n",
    "        for file in file_list:\n",
    "            read_file = pd.read_csv(file_path + file)\n",
    "            all_df = pd.concat([all_df,read_file])\n",
    "        before_len = all_df.shape[0] # before\n",
    "\n",
    "        #중복제거\n",
    "        all_df = all_df.drop_duplicates('full_text')\n",
    "\n",
    "        #필터링\n",
    "        all_df = all_df.fillna('')\n",
    "        filtered = all_df.full_text.apply(lambda x : any(ele in x for ele in filter_word))\n",
    "        clean_file = all_df[~filtered]\n",
    "        filtered = clean_file.title.apply(lambda x : any(ele in x for ele in filter_word))\n",
    "        clean_file = clean_file[~filtered]\n",
    "        after_len  = clean_file.shape[0] #after\n",
    "\n",
    "        #연도 달 추가\n",
    "        clean_file['year'] = clean_file.post_dates.apply(lambda dates : int(dates.split(\"-\")[0]))\n",
    "        clean_file['month'] = clean_file.post_dates.apply(lambda dates : int(dates.split(\"-\")[1]))\n",
    "        clean_file = clean_file[['post_dates','year', 'month', 'title', 'full_text', 'url']]\n",
    "        #저장 \n",
    "        clean_file.to_csv(f'./output/크롤링/통합/{folder}_통합_{after_len}.csv',index = False)\n",
    "        \n",
    "        result_dict['keyword'].append(folder)\n",
    "        result_dict['before_len'].append(before_len)\n",
    "        result_dict['after_len'].append(after_len)\n",
    "        \n",
    "                \n",
    "        if verbose == True:\n",
    "            print('시작전row:',before_len)   \n",
    "            print('종료후row:',after_len)\n",
    "            print(folder,\"완료\")\n",
    "            print('---------------------')\n",
    "    #총결과 출력\n",
    "    result_df = pd.DataFrame(result_dict)\n",
    "    result_df['diff'] = result_df['before_len'] -result_df['after_len']\n",
    "    result_df['loss'] = round(result_df['diff']/result_df['before_len'],4) *100\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #일부분일 경우 \n",
    "# sep_list = [\"광진해변 +양양\",\"광진해수욕장 +양양\"]\n",
    "# crawling_merge(path, verbose=True, not_all=True, sep_list=sep_list)\n",
    "#전체\n",
    "result_df = crawling_merge(path, verbose=True)\n",
    "result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}