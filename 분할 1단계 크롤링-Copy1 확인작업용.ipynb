{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 목적\n",
    "* 네이버 블로그에 검색어를 넣었을 때 나오는 블로그들을 크롤링\n",
    "* 검색시 방법은 특정기간, 월별, 연별 검색에 따라 사용방법이 다소다름 (현재 연도최적화)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선행설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T01:40:53.001768Z",
     "start_time": "2020-06-02T01:40:52.999767Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#선행설치\n",
    "# # 크롤링\n",
    "# !pip install beautifulsoup4\n",
    "# !pip install requests\n",
    "# # 자연어처리\n",
    "# !pip install konlpy (JDK 설치가 되어있어야함 )\n",
    "# # 워드클라우드\n",
    "# !pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T04:48:44.873146Z",
     "start_time": "2020-06-15T04:48:44.091906Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import\n",
    "\n",
    "from tqdm import tqdm_notebook  # 진행과정 시각화\n",
    "from datetime import timedelta  # 시간날짜\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "import requests\n",
    "import urllib.request\n",
    "import urllib.error\n",
    "import urllib.parse\n",
    "from bs4 import BeautifulSoup  # 크롤링\n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML('<style>.container {width:100% !important; }</style>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T04:48:44.879145Z",
     "start_time": "2020-06-15T04:48:44.874143Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def del_outword(string):\n",
    "    '''크롤링 후 이모티콘, \\u200b과 같은 문자가 아닌 것 제거\n",
    "    [출처](https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python)\n",
    "    '''\n",
    "    #이모지제거\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                u\"\\U00002702-\\U000027B0\"\n",
    "                u\"\\U0001f926-\\U0001f937\"\n",
    "                u'\\U00010000-\\U0010ffff'\n",
    "                u\"\\u200d\"\n",
    "                u\"\\u2640-\\u2642\"\n",
    "                u\"\\u2600-\\u2B55\"\n",
    "                u\"\\u23cf\"\n",
    "                u\"\\u23e9\"\n",
    "                u\"\\u231a\"\n",
    "                u\"\\u3030\"\n",
    "                u\"\\ufe0f\"\n",
    "    \"]+\", flags=re.UNICODE)\n",
    "\n",
    "    #분석에 어긋나는 불용어구 제외 (특수문자, 의성어)\n",
    "    han = re.compile(r'[ㄱ-ㅎㅏ-ㅣ!?~\"^_\\n\\r#\\ufeff\\u200d\\u200b\\u7643\\ufffd\\u682e\\u62c4]+')\n",
    "    \n",
    "    string = emoji_pattern.sub(r'',string)\n",
    "    string = han.sub(r'',string)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T04:48:45.493889Z",
     "start_time": "2020-06-15T04:48:45.487896Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def time_change(x):\n",
    "    '''검색결과에 있는 문자를 날짜로 변경\n",
    "    네이버 블로그 크롤링시 작성일자가 1분전/1시간전/1일전으로 나타는 경우가 가끔씩 존재\n",
    "    이러한 패턴을 일반적인 YY-MM-DD형태로 변환함\n",
    "    그리고 월별 계산이 중요하므로 모든 데이터는 1일로 통일\n",
    "    \n",
    "    Return\n",
    "    -------\n",
    "    x : datetime\n",
    "        날짜형형태로 전환\n",
    "        \n",
    "    Example\n",
    "    -------\n",
    "    >>> x = \"47분 전\"\n",
    "    >>> time_change(x)\n",
    "    datetime.datetime(2020, 6, 1, 0, 0)\n",
    "    \n",
    "    >>> x2 = \"2019.01.31\"\n",
    "    >>> time_change(x2)\n",
    "    datetime.datetime(2019, 1, 1, 0, 0)\n",
    "    '''\n",
    "    \n",
    "    min_pattern = re.compile('[0-9]+'+\"분 전\")\n",
    "    hour_pattern = re.compile('[0-9]+'+\"시간 전\")\n",
    "    day_pattern = re.compile('[0-9]+'+\"일 전\")\n",
    "\n",
    "    today = datetime.datetime.today().date()\n",
    "    # 일자\n",
    "    if \"일\" in x :\n",
    "        d = re.findall(day_pattern, x)[0][0]\n",
    "        x = today - timedelta(days=int(d))\n",
    "    elif \"시간\" in x:\n",
    "        d = re.findall(hour_pattern, x)[0]\n",
    "        x = today\n",
    "    elif \"분\" in x:\n",
    "        d = re.findall(min_pattern, x)[0]\n",
    "        x = today\n",
    "    elif x == \"어제\":\n",
    "        x = today - timedelta(days=1)\n",
    "    elif type(x) == str: # 'YY.NN.DD'형태\n",
    "        x = datetime.datetime.strptime(x.replace('.', '-')[:-1], '%Y-%m-%d')\n",
    "    \n",
    "    #모든일자를 1일로 통일\n",
    "    x = datetime.datetime.strptime(x.strftime('%Y-%m')+\"-01\",\"%Y-%m-%d\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T04:48:46.557130Z",
     "start_time": "2020-06-15T04:48:46.544136Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def naver_blog_crawling(keyword, start_num=1, end_num=101, date_option=0, date_from='', date_to='', save=True):\n",
    "    '''네이버 블로그 크롤링 함수\n",
    "    네이버 블로그 검색결과를 크롤링하며, 1페이지당 10개씩을 검색한다\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    keyword(string) : 검색하고 싶은 키워드를 넣는다 \"keyword +필수어\" 형태로 필수단어 추가 가능\n",
    "    start_num(int) : (default = 1)  시작할 위치, 1로 끝나는 단위 추천\n",
    "    end_num(int) : (default = 101) 끝나는 위치, 1로 끝나는 단위 추천\n",
    "    date_option(int) : (default = 0) 주어지는 숫자에 의해 검색방법이 변경됨\n",
    "                         0 : 전체, 2 : 1일, 3 : 1주, 4 : 1개월, 6 : 6개월, 7 : 1년, 8 : 기간지정\n",
    "    date_from(YYYYMMDD) : (default = \"\") date_option이 8일때 사용 검색 시작일자를 지정\n",
    "    date_to(YYYYMMDD) : (default = \"\"), date_option이 8일때 사용 검색 마지막일자를 지정\n",
    "    save(bool) : (default = True)csv로 저장 여부 결정\n",
    "    \n",
    "    Returns \n",
    "    -------\n",
    "    crawling_df : DataFrame\n",
    "        post_dates title  full_text         url\n",
    "      0 2010-01-01 title  [full_text]       http://blog.naver.com/PostView.nhn?blogId=wend...  \n",
    "    \n",
    "    real_length : int\n",
    "        crawling_df의 row수 \n",
    "    '''\n",
    "    # url 찾는 패턴\n",
    "    pattern = re.compile('href=\"'+'[A-z0-9\\:\\/\\&\\;\\.\\?\\=]+')\n",
    "\n",
    "    # 저장위치\n",
    "    postdates = []\n",
    "    strings = []\n",
    "    urls = []\n",
    "    titles = []\n",
    "    output_error = []\n",
    "    connection_error = []\n",
    "    count = 1\n",
    "\n",
    "    # keyword와 시작넘버만 바꾸면서 진행하게끔\n",
    "    base_url = 'https://search.naver.com/search.naver?date_from={date_from}&date_option={date_option}&date_to={date_to}&dup_remove=1&nso=&post_blogurl=&post_blogurl_without=&query={keyword}&sm=tab_pge&srchby=all&st=sim&where=post&start={start}'\n",
    "\n",
    "    try:\n",
    "        # check length\n",
    "        search_list = base_url.format(keyword=keyword, start=start_num,\n",
    "                                      date_option=date_option, date_from=date_from, date_to=date_to)\n",
    "        response = requests.get(search_list)\n",
    "        soup = BeautifulSoup(response.content, 'lxml')\n",
    "        max_searched = soup.select(\"div.section_head\")[0].text.split('/')[1]\n",
    "        max_searched = int(re.sub('[가-힣 ,]+', \"\", max_searched))\n",
    "        end_num = max_searched\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # for문 돌려야하는 부분(각 검색결과의 시작은 1이고, 10개씩 보여짐,)\n",
    "    for i in tqdm_notebook(range(start_num, end_num+10, 10), desc = 'section'):\n",
    "        search_list = base_url.format(keyword=keyword, start=i,\n",
    "                                      date_option=date_option, date_from=date_from, date_to=date_to)\n",
    "        response = requests.get(search_list)\n",
    "\n",
    "        if response.status_code is 200:\n",
    "            # 1번 검색시 10개의 결과가 출력 따라서 section은 총 10개\n",
    "            soup = BeautifulSoup(response.content, 'lxml')\n",
    "            sections = soup.findAll('li', attrs={'class': 'sh_blog_top'})\n",
    "\n",
    "            for section in sections:\n",
    "                try:\n",
    "                    # href부분만 가져오기 어려워서 정규표현식으로 검색\n",
    "                    url = re.findall(pattern, str(section))[0].replace(\n",
    "                        '?Redirect=Log&amp;logNo=', '/').replace('href=\"', '')\n",
    "                    title = section.select_one('a.txt84').text\n",
    "                    date = section.select_one('dd.txt_inline').text.strip()\n",
    "\n",
    "                    # 블로그 url안에 들어가기(아직 크롤링불가)\n",
    "                    get_blog_post_content_code = requests.get(url)\n",
    "                    get_blog_post_content_text = get_blog_post_content_code.text\n",
    "                    get_blog_post_content_soup = BeautifulSoup(\n",
    "                        get_blog_post_content_text, 'lxml')\n",
    "\n",
    "                    # 크롤링가능한 url에 접속\n",
    "                    real_blog_post_url = \"http://blog.naver.com\" + \\\n",
    "                        get_blog_post_content_soup.select('#mainFrame')[\n",
    "                            0].get('src')\n",
    "                    get_real_blog_post_content_code = requests.get(\n",
    "                        real_blog_post_url)\n",
    "                    get_real_blog_post_content_text = get_real_blog_post_content_code.text\n",
    "                    get_real_blog_post_content_soup = BeautifulSoup(\n",
    "                        get_real_blog_post_content_text, 'lxml')\n",
    "\n",
    "                    # url (에러나면 위에서부터 에러남)\n",
    "                    urls.append(real_blog_post_url)\n",
    "                    # 블로그명\n",
    "                    titles.append(title)\n",
    "                    # 날짜\n",
    "                    postdates.append(date)\n",
    "\n",
    "                    # 본문  (postviewarea 패턴과 se-main-container 2가지 유형이 있어 분리함)\n",
    "                    try:\n",
    "                        blog_post_content = get_real_blog_post_content_soup.select(\n",
    "                            'div#postViewArea')\n",
    "                        if len(blog_post_content) == 0:\n",
    "                            blog_post_content = get_real_blog_post_content_soup.select(\n",
    "                                'div.se-main-container')\n",
    "                            if len(blog_post_content) == 0:\n",
    "                                blog_post_content = get_real_blog_post_content_soup.select(\n",
    "                                    'div.se_component_wrap.sect_dsc.__se_component_area')\n",
    "\n",
    "                        string = \"\"\n",
    "                        for sentence in blog_post_content[0].stripped_strings:\n",
    "                            string += \" \"+sentence.replace('\\xa0', \" \")\n",
    "                            # 비언어 텍스트제거\n",
    "                            string = del_outword(string)\n",
    "                        # 공백에러대처\n",
    "                        blank_check = string.replace(\" \", \"\")\n",
    "                        if len(blank_check) == 0:\n",
    "                            strings.append([\"X\"])\n",
    "                        else:\n",
    "                            strings.append([string])\n",
    "                        count += 1\n",
    "                    except:\n",
    "                        strings.append([\"X\"])\n",
    "                        output_error.append(count)\n",
    "                        count += 1\n",
    "\n",
    "                except Exception as ex:\n",
    "                    # print('가져오기에러 {num}번째'.format(num = count),ex)\n",
    "                    output_error.append(count)\n",
    "                    count += 1\n",
    "                    pass\n",
    "        else:\n",
    "            # print('연결오류 {num}번째'.format(num = count),response.status_code)\n",
    "            connection_error.append(count)\n",
    "            count += 1\n",
    "\n",
    "    out_length = len(output_error+connection_error)\n",
    "#     real_length = end_num-start_num+10-out_length\n",
    "\n",
    "    crawling_df = pd.DataFrame(\n",
    "        {\"post_dates\": postdates, \"title\": titles, \"full_text\": strings, \"url\": urls})\n",
    "    crawling_df['post_dates'] = crawling_df['post_dates'].apply(\n",
    "        lambda x: time_change(x))\n",
    "    # 중복제거\n",
    "    crawling_df.drop_duplicates(\"url\", inplace=True)\n",
    "    crawling_df.reset_index(drop=True, inplace=True)\n",
    "    real_length = crawling_df.shape[0]\n",
    "\n",
    "    # 결과출력\n",
    "#     print(\"검색한 길이:\", end_num-start_num+10)\n",
    "#     print(\"제외된 길이:\", out_length)\n",
    "#     print(\"검색된 길이:\", real_length)\n",
    "\n",
    "    if save == True:\n",
    "        today = datetime.datetime.today().date()\n",
    "        str(today)\n",
    "        os.makedirs(\n",
    "            './output/크롤링/{keyword}'.format(keyword=keyword), exist_ok=True)\n",
    "        # 저장이름 \"기간_키워드_길이_날짜\" ex) 20160501~20160531_물치리 +강원도_9_2020-05-07\n",
    "        crawling_df.to_csv(f\"./output/크롤링/{keyword}/{date_from}~{date_to}_{keyword}_{real_length}_{today}.csv\", encoding='utf-8', index=False)\n",
    "    return crawling_df, real_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T04:48:47.262289Z",
     "start_time": "2020-06-15T04:48:47.256298Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def make_date_list(start_year,end_year,month_gap = 1,year_gap = 1, types = 'month'):\n",
    "    '''검색에 사용할 날짜 list를 생성\n",
    "    시작년도, 마지막년도를 입력하고 월별간격, 연별 간격을 입력하면\n",
    "    검색에 사용할 \"YYMMDD\"형태의 날짜 list를 반환\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    start_year(int) : 검색을 시작할 연도\n",
    "    end_year(int) : 검색을 종료할 연도\n",
    "    month_gap(int) : 몇개월 단위로 검색할 것인지\n",
    "    year_gap(int) : 몇년 단위로 검색할 것인지\n",
    "    types(string) : 'year' or 'month'로 연간검색 혹은 월간검색지정\n",
    "    \n",
    "    Returns \n",
    "    -------\n",
    "    start_date, end_date : list\n",
    "        YYMMDD형태의 string형태의 날짜들은 반환한다\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> make_date_list(start_year = 2010, end_year = 2011,month_gap = 1,year_gap = 1, types = 'month')\n",
    "    start_date = ['20100101', '20100701', '20110101', '20110701']\n",
    "    end_date = ['20100131', '20100731', '20110131', '20110731']\n",
    "    \n",
    "    >>> make_date_list(start_year = 2010, end_year = 2013,year_gap = 1, types = 'year')\n",
    "    start_date = ['20100101', '20110101', '20120101', '20130101']\n",
    "    end_date = ['20101231', '20111231', '20121231', '20131231']\n",
    "    '''\n",
    "    #일자\n",
    "    month_gap = month_gap*100\n",
    "    start_month = []\n",
    "    end_month = []\n",
    "    \n",
    "    #MMDD 형태 추출\n",
    "    for date in range(101,1202,month_gap):\n",
    "        start_month.append(date)\n",
    "    start_month = list(map(lambda x : '{:0>4}'.format(str(x)),start_month))\n",
    "\n",
    "    for date in range(131,1232,month_gap):\n",
    "        end_month.append(date)\n",
    "    end_month = list(map(lambda x : '{:0>4}'.format(str(x)),end_month))\n",
    "\n",
    "    start_date = []\n",
    "    end_date = []\n",
    "    \n",
    "    #YYMMDD 형태로 추출\n",
    "    if types.lower() == 'month':\n",
    "        for year in range(start_year,end_year+1,year_gap):\n",
    "            for date in start_month:\n",
    "                start_date.append(str(year)+date)\n",
    "            for date in end_month:\n",
    "                end_date.append(str(year)+date)\n",
    "    elif types.lower() == 'year':\n",
    "        for year in range(start_year,end_year+1,year_gap):\n",
    "            start_date.append(str(year)+'0101')\n",
    "            end_date.append(str(year)+'1231')\n",
    "            \n",
    "        \n",
    "    return start_date,end_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 검색방법 및 불용어설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T04:48:48.553743Z",
     "start_time": "2020-06-15T04:48:48.551742Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 특정기간 설정\n",
    "word_list = [\"물치\",\"설악해수욕장\",\"낙산\",\"오산\",\"수산항\",\"동호\",\"하조대\",\"하광정리\",\"기사문\",\"동산\",\"인구\",\"광진\",\"남애\"]\n",
    "mustword = \"양양\"\n",
    "\n",
    "start_num = 1\n",
    "end_num = 701\n",
    "date_option = 8\n",
    "date_from = \"20150101\"\n",
    "date_to = \"20151231\"\n",
    "today = datetime.datetime.today().date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T04:49:05.342275Z",
     "start_time": "2020-06-15T04:49:05.326640Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#월별 설정\n",
    "word_list =[\"머신러닝\"]\n",
    "mustword = \"python\"\n",
    "start_num = 1\n",
    "end_num = 991\n",
    "date_option = 8\n",
    "start_year = 2010\n",
    "end_year = 2011\n",
    "month_gap = 6\n",
    "year_gap = 1\n",
    "today = datetime.datetime.today().date()\n",
    "#날짜범위함수 \n",
    "date_from,date_to = make_date_list(start_year,end_year,month_gap,year_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T04:49:20.544250Z",
     "start_time": "2020-06-15T04:49:20.479647Z"
    }
   },
   "outputs": [],
   "source": [
    "#불용어\n",
    "sw = list(pd.read_excel(\"stopword(cp949).xlsx\",encoding = 'cp949')['불용어']) #불용어 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T04:49:21.468982Z",
     "start_time": "2020-06-15T04:49:21.463990Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def searching_all(word_list,date_from, date_to, start_num = 1, end_num = 991, date_option = 8, mustword = \"\"):\n",
    "    ''' 검색할 단어가 많을경우 사용\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    word_list(list): 검색할 단어들 \n",
    "    date_from(list or int) : 검색을 시작할 날짜\n",
    "    date_to(list or int) : 검색을 마칠 날짜 \n",
    "    start_num(int) : (default = 1) 검색시작할 페이지 \n",
    "    end_num(int) : (default= 991) 검색을 마칠 페이지 #네이버검색은 최대 1000개의 결과물만 보여줌\n",
    "    mustword(string) : (default = '') 필수단어 지정\n",
    "    \n",
    "    '''\n",
    "    #키워드별 \n",
    "    for i in tqdm_notebook(range(0,len(word_list)), desc = 'Total'):\n",
    "        keyword = word_list[i] + \" +\" + mustword\n",
    "        print('{num}번째/{total_num}번째 {keyword}'.format(num = i+1, total_num = len(word_list),keyword = keyword))\n",
    "        #날짜가 연별,월별인경우 \n",
    "        if type(date_from) == list:\n",
    "            for date_num in tqdm_notebook(range(0,len(date_from)),desc = \"Time\"):\n",
    "                date_from_one = date_from[date_num]\n",
    "                date_to_one = date_to[date_num]\n",
    "                crawling_df, real_length = naver_blog_crawling(keyword, start_num, end_num, date_option, date_from_one, date_to_one)\n",
    "#                 output_graph(okt,crawling_df,keyword,real_length,sw,date_from_one,date_to_one,unique=False)\n",
    "        #단일날짜의 경우 \n",
    "        else:\n",
    "            crawling_df, real_length = naver_blog_crawling(keyword, start_num, end_num, date_option, date_from, date_to)\n",
    "#             output_graph(okt,crawling_df,keyword,real_length,sw,date_from,date_to,unique=False)\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T04:49:47.847857Z",
     "start_time": "2020-06-15T04:49:23.047764Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3313e75470f943d993cbd6916a48a9d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Total', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째/1번째 머신러닝 +python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d7e262fae94c24874425937f6ecd1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Time', max=4.0, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:53: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6607b16cde543d4b275245381c3bbe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='section', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7bd491c384a4868bfab164fede8f2e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='section', style=ProgressStyle(description_width='initial'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea5eefadc9f642c2aa3dc5cfe8c3e282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='section', max=1.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a7f202da13417288ec592e9bdb53ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='section', style=ProgressStyle(description_width='initial'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "searching_all(word_list = word_list, mustword = mustword, start_num = start_num, end_num = end_num, date_option = date_option, date_from = date_from, date_to = date_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 확인작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T01:30:42.305923Z",
     "start_time": "2020-06-02T01:30:42.303923Z"
    }
   },
   "outputs": [],
   "source": [
    "keyword = '기사문 +강원도'\n",
    "date_from = 20100101\n",
    "date_to = 20100131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T01:32:36.619467Z",
     "start_time": "2020-06-02T01:32:36.528447Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-195d8e74c5c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmax_searched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"div.section_head\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mmax_searched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[가-힣 ,]+'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_searched\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mend_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_searched\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "    # keyword와 시작넘버만 바꾸면서 진행하게끔\n",
    "    base_url = 'https://search.naver.com/search.naver?date_from={date_from}&date_option={date_option}&date_to={date_to}&dup_remove=1&nso=&post_blogurl=&post_blogurl_without=&query={keyword}&sm=tab_pge&srchby=all&st=sim&where=post&start={start}'\n",
    "    \n",
    "    #check length\n",
    "    search_list = base_url.format(keyword=keyword, start=start_num,\n",
    "                                      date_option=date_option, date_from=date_from, date_to=date_to)\n",
    "    response = requests.get(search_list)\n",
    "    soup = BeautifulSoup(response.content, 'lxml')\n",
    "    max_searched = soup.select(\"div.section_head\")[0].text.split('/')[1]\n",
    "    max_searched = int(re.sub('[가-힣 ,]+',\"\",max_searched))\n",
    "    end_num = max_searched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T01:31:29.587480Z",
     "start_time": "2020-06-02T01:31:29.584480Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://search.naver.com/search.naver?date_from=20100101&date_option=8&date_to=20100131&dup_remove=1&nso=&post_blogurl=&post_blogurl_without=&query=기사문 +강원도&sm=tab_pge&srchby=all&st=sim&where=post&start=1'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "273px",
    "left": "1310px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
