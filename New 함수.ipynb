{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 목적\n",
    "* 블로그 내용을 긁어와서 연관분석 진행\n",
    "1. keyword관련 블로그 크롤링 \n",
    "    정확도 기준으로 긁어오되 날짜도 같이 가져와서 나중 어떤 날짜에 집중되어 있는지 확인\n",
    "    한 블로그당 단어빈도수 분석(필요할까)\n",
    "2. 블로그 내 단어 토크나이즈하고 \n",
    "3. 연관분석실시\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T05:37:17.198255Z",
     "start_time": "2020-03-31T05:37:07.916960Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting konlpy\n",
      "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from konlpy) (0.3.9)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from konlpy) (1.18.1)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from konlpy) (4.2.1)\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from konlpy) (4.6.0)\n",
      "Collecting JPype1>=0.7.0\n",
      "  Downloading JPype1-0.7.2-cp36-cp36m-win_amd64.whl (1.3 MB)\n",
      "Collecting tweepy>=3.7.0\n",
      "  Downloading tweepy-3.8.0-py2.py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: requests>=2.11.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tweepy>=3.7.0->konlpy) (2.18.4)\n",
      "Requirement already satisfied: PySocks>=1.5.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tweepy>=3.7.0->konlpy) (1.6.8)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tweepy>=3.7.0->konlpy) (1.11.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2019.11.28)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Installing collected packages: JPype1, oauthlib, requests-oauthlib, tweepy, konlpy\n",
      "Successfully installed JPype1-0.7.2 konlpy-0.5.2 oauthlib-3.1.0 requests-oauthlib-1.3.0 tweepy-3.8.0\n"
     ]
    }
   ],
   "source": [
    "# # 선행설치\n",
    "# !pip install beautifulsoup4\n",
    "# !pip install requests\n",
    "# !pip install lxm\n",
    "# # 연관분석\n",
    "# !pip install apyori\n",
    "# # 자연어처리\n",
    "# !pip install konlpy (JDK 설치가 되어있어야함 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T08:20:04.424443Z",
     "start_time": "2020-03-31T08:20:03.980352Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import math\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import urllib.request\n",
    "import urllib.error\n",
    "import urllib.parse\n",
    "from bs4 import BeautifulSoup #크롤링\n",
    "\n",
    "import konlpy\n",
    "from konlpy.tag import Komoran #자연어처리\n",
    "from apyori import apriori #연관분석\n",
    "from tqdm import tqdm_notebook #진행과정 시각화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T08:52:54.042421Z",
     "start_time": "2020-03-31T08:52:54.039421Z"
    }
   },
   "outputs": [],
   "source": [
    "#페이지 카운트 수로 api호출된다\n",
    "#1,000개일때 3분 \n",
    "naver_client_id = \"uG5V8KhGUcRmRCtBzj7d\"\n",
    "naver_client_secret = \"6MkFrc1bUG\"\n",
    "keyword = '양양'\n",
    "display_count = 100\n",
    "page_count = 100\n",
    "sort_type = 'sim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T08:52:54.832380Z",
     "start_time": "2020-03-31T08:52:54.823378Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_blog_post(keyword, display_count, page_count, sort_type,save = True):\n",
    "    '''\n",
    "    keyword : 검색하고 싶은 키워드\n",
    "    display_count : 한 페이지당 표출할 개수 min = 10, max = 100\n",
    "    page_count : 총 진행할 페이지의 수 min = 1, max = 1000\n",
    "    sort_type : 정렬옵션 \"sim\" (유사도순), \"date\" (날짜순)\n",
    "    ''' \n",
    "    #날짜와 본문내용 저장\n",
    "    postdates = []\n",
    "    strings = []\n",
    "    urls = []\n",
    "    titles = []\n",
    "    \n",
    "    encode_keyword = urllib.parse.quote(keyword)\n",
    "    # get_blog_search_result_pagination_count로 처리할 수있는 페이지수를 1부터 페이지수까지 까지 각각 하나씩 긁어옴 \n",
    "    for i in tqdm_notebook(range(1, page_count + 1),desc = \"page work\"):\n",
    "        url = \"https://openapi.naver.com/v1/search/blog?query=\" + encode_keyword + \"&display=\" + str(\n",
    "            display_count) + \"&start=\" + str(i) + \"&sort=\" + sort_type\n",
    "\n",
    "        request = urllib.request.Request(url)\n",
    "\n",
    "        request.add_header(\"X-Naver-Client-Id\", naver_client_id)\n",
    "        request.add_header(\"X-Naver-Client-Secret\", naver_client_secret)\n",
    "\n",
    "        response = urllib.request.urlopen(request)\n",
    "        response_code = response.getcode()\n",
    "         \n",
    "        if response_code is 200:\n",
    "            response_body = response.read()\n",
    "            response_body_dict = json.loads(response_body.decode('utf-8'))\n",
    "        #items의 개수만큼씩 진행\n",
    "            for j in range(0, len(response_body_dict['items'])):\n",
    "                blog_post_url = response_body_dict['items'][j]['link'].replace(\"amp;\", \"\")\n",
    "                urls.append(blog_post_url)\n",
    "                #블로그 url안에 들어가기(아직 크롤링불가)\n",
    "                get_blog_post_content_code = requests.get(blog_post_url)\n",
    "                get_blog_post_content_text = get_blog_post_content_code.text\n",
    "                get_blog_post_content_soup = BeautifulSoup(get_blog_post_content_text, 'lxml')\n",
    "                #크롤링가능한 url에 접속\n",
    "                real_blog_post_url = \"http://blog.naver.com\" + get_blog_post_content_soup.select('#mainFrame')[0].get('src')\n",
    "                get_real_blog_post_content_code = requests.get(real_blog_post_url)\n",
    "                get_real_blog_post_content_text = get_real_blog_post_content_code.text\n",
    "                get_real_blog_post_content_soup = BeautifulSoup(get_real_blog_post_content_text, 'lxml')\n",
    "                #본문부분 추출 \n",
    "                blog_post_content = get_real_blog_post_content_soup.select('div#postViewArea')\n",
    "                if len(blog_post_content) == 0:\n",
    "                    blog_post_content = get_real_blog_post_content_soup.select('div.se-main-container')\n",
    "\n",
    "                #전체 텍스트 \n",
    "                string = \"\"\n",
    "                for sentence in blog_post_content[0].stripped_strings:\n",
    "                    string += \" \"+sentence.replace('\\xa0',\" \")\n",
    "                #공백제거 \n",
    "                string = string.replace('\\u200b',\" \")\n",
    "                string = string.replace('\\n',\" \")\n",
    "                strings.append([string]) \n",
    "\n",
    "                #포스트날짜\n",
    "                postdate = datetime.datetime.strptime(response_body_dict['items'][j]['postdate'],\"%Y%m%d\").strftime(\"%y.%m.%d\")\n",
    "                postdates.append(postdate)\n",
    "                \n",
    "                #제목\n",
    "                remove_html_tag = re.compile('<.*?>')\n",
    "                title = re.sub(remove_html_tag, '', response_body_dict['items'][j]['title'])\n",
    "                titles.append(title)\n",
    "                \n",
    "    # utf-8형식으로 저장하면 엑셀에서 열때 에러나지만, load는 가능\n",
    "    if save == True:\n",
    "        crawling_df = pd.DataFrame({\"post_dates\":postdates, \"title\":titles,\"full_text\":strings, \"url\":urls})\n",
    "        crawling_df.to_csv(keyword+\"_\"+str(display_count* page_count)+\".csv\",encoding='utf-8',index= False)\n",
    "    return crawling_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T09:06:40.211322Z",
     "start_time": "2020-03-31T08:52:56.246143Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be6c7f5f55134221819f759d58c51eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='page work', style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-213-9f53351215b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcrawling_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_blog_post\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpage_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-212-e8e497e3e70f>\u001b[0m in \u001b[0;36mget_blog_post\u001b[1;34m(keyword, display_count, page_count, sort_type, save)\u001b[0m\n\u001b[0;32m     38\u001b[0m                 \u001b[0mget_blog_post_content_soup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_blog_post_content_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[1;31m#크롤링가능한 url에 접속\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m                 \u001b[0mreal_blog_post_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"http://blog.naver.com\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mget_blog_post_content_soup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'#mainFrame'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'src'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m                 \u001b[0mget_real_blog_post_content_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_blog_post_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m                 \u001b[0mget_real_blog_post_content_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_blog_post_content_code\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "crawling_df = get_blog_post(keyword, display_count, page_count, sort_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T08:51:03.898120Z",
     "start_time": "2020-03-31T08:51:03.889117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_dates</th>\n",
       "      <th>title</th>\n",
       "      <th>full_text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20.03.28</td>\n",
       "      <td>양양서핑 우와 뜨겁네!</td>\n",
       "      <td>[ 오늘은 양양 서핑 으로 동해에서 가장 핫한 서핑샵 플리즈웨잇서프를 소개해 드리려...</td>\n",
       "      <td>https://blog.naver.com/shakyamuni?Redirect=Log...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20.03.07</td>\n",
       "      <td>푸짐했던 양양 맛집</td>\n",
       "      <td>[ 얼마전에 가족들과 양양에 놀러갔다가 아주 괜찮은 양양 맛집을 찿아갔어요~ 대게 ...</td>\n",
       "      <td>https://blog.naver.com/collier13?Redirect=Log&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>20.03.25</td>\n",
       "      <td>양양 설해원 마운틴스테이</td>\n",
       "      <td>[ 한달전쯤 갔던 곳인데 이제야 리뷰를 남기네요;;;;   강원도 양양에 위치한 설...</td>\n",
       "      <td>https://blog.naver.com/rockncat?Redirect=Log&amp;l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20.03.26</td>\n",
       "      <td>양양 낙산비치호텔, 마운틴뷰 덕에 상쾌했던 숙소-♬</td>\n",
       "      <td>[   지난 속초 여행에서 가고 싶었지만 시간이 부족해서 가지 못했던 설악산을 가기...</td>\n",
       "      <td>https://blog.naver.com/eruriee?Redirect=Log&amp;lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20.03.16</td>\n",
       "      <td>양양 쏠비치 리조트 2박3일 맛집투어</td>\n",
       "      <td>[ 오랜만에 양양 쏠비치 다녀왔어요- 날씨가 아직도 춥기에 완전 무장을 하고 다녀왔...</td>\n",
       "      <td>https://blog.naver.com/ashacs1?Redirect=Log&amp;lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>20.03.10</td>\n",
       "      <td>동산항, 양양~  '파머스키친'</td>\n",
       "      <td>[ 검증된 맛집을 찾아 갔다.   죽도해변에 있었던 '파머스키친'   죽도가니 없어...</td>\n",
       "      <td>https://blog.naver.com/gogoaec?Redirect=Log&amp;lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>20.03.10</td>\n",
       "      <td>양양 죽도해수욕장, 남애항도 돌아보았네요</td>\n",
       "      <td>[ 양양 휴휴암에서 바로 발길을 돌리자니 아쉬움이 남아서 인근 죽도해변과 남애항을 ...</td>\n",
       "      <td>https://blog.naver.com/bmw8888?Redirect=Log&amp;lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>20.02.19</td>\n",
       "      <td>먹을 복 터졌던 양양 맛집</td>\n",
       "      <td>[ 얼마 전 친구들과 함께 양양에 다녀왔어요 그곳에서 싱싱한 해산물들 잔뜩 먹고 돌...</td>\n",
       "      <td>https://blog.naver.com/zndkdvndkd?Redirect=Log...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>20.03.17</td>\n",
       "      <td>양양 산촌생등심 - 짠내투어 한우등심 맛집으로 나왔던 그 곳</td>\n",
       "      <td>[ ﻿ 안녕하세요 케이입니다. 저번에 양양 배낚시 다녀오면서 저녁에 네이버 검색으로...</td>\n",
       "      <td>https://blog.naver.com/bluekei9?Redirect=Log&amp;l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>20.03.15</td>\n",
       "      <td>국내여행 :: 강원도 속초-양양-강릉 1</td>\n",
       "      <td>[ 코로나 여파로 이틀 연속 오전만 일하고 오후는 무노동... 무노동무임금 프리랜서...</td>\n",
       "      <td>https://blog.naver.com/yansy?Redirect=Log&amp;logN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    post_dates                              title  \\\n",
       "0     20.03.28                       양양서핑 우와 뜨겁네!   \n",
       "1     20.03.07                         푸짐했던 양양 맛집   \n",
       "2     20.03.25                      양양 설해원 마운틴스테이   \n",
       "3     20.03.26       양양 낙산비치호텔, 마운틴뷰 덕에 상쾌했던 숙소-♬   \n",
       "4     20.03.16               양양 쏠비치 리조트 2박3일 맛집투어   \n",
       "..         ...                                ...   \n",
       "995   20.03.10                  동산항, 양양~  '파머스키친'   \n",
       "996   20.03.10             양양 죽도해수욕장, 남애항도 돌아보았네요   \n",
       "997   20.02.19                     먹을 복 터졌던 양양 맛집   \n",
       "998   20.03.17  양양 산촌생등심 - 짠내투어 한우등심 맛집으로 나왔던 그 곳   \n",
       "999   20.03.15             국내여행 :: 강원도 속초-양양-강릉 1   \n",
       "\n",
       "                                             full_text  \\\n",
       "0    [ 오늘은 양양 서핑 으로 동해에서 가장 핫한 서핑샵 플리즈웨잇서프를 소개해 드리려...   \n",
       "1    [ 얼마전에 가족들과 양양에 놀러갔다가 아주 괜찮은 양양 맛집을 찿아갔어요~ 대게 ...   \n",
       "2    [ 한달전쯤 갔던 곳인데 이제야 리뷰를 남기네요;;;;   강원도 양양에 위치한 설...   \n",
       "3    [   지난 속초 여행에서 가고 싶었지만 시간이 부족해서 가지 못했던 설악산을 가기...   \n",
       "4    [ 오랜만에 양양 쏠비치 다녀왔어요- 날씨가 아직도 춥기에 완전 무장을 하고 다녀왔...   \n",
       "..                                                 ...   \n",
       "995  [ 검증된 맛집을 찾아 갔다.   죽도해변에 있었던 '파머스키친'   죽도가니 없어...   \n",
       "996  [ 양양 휴휴암에서 바로 발길을 돌리자니 아쉬움이 남아서 인근 죽도해변과 남애항을 ...   \n",
       "997  [ 얼마 전 친구들과 함께 양양에 다녀왔어요 그곳에서 싱싱한 해산물들 잔뜩 먹고 돌...   \n",
       "998  [ ﻿ 안녕하세요 케이입니다. 저번에 양양 배낚시 다녀오면서 저녁에 네이버 검색으로...   \n",
       "999  [ 코로나 여파로 이틀 연속 오전만 일하고 오후는 무노동... 무노동무임금 프리랜서...   \n",
       "\n",
       "                                                   url  \n",
       "0    https://blog.naver.com/shakyamuni?Redirect=Log...  \n",
       "1    https://blog.naver.com/collier13?Redirect=Log&...  \n",
       "2    https://blog.naver.com/rockncat?Redirect=Log&l...  \n",
       "3    https://blog.naver.com/eruriee?Redirect=Log&lo...  \n",
       "4    https://blog.naver.com/ashacs1?Redirect=Log&lo...  \n",
       "..                                                 ...  \n",
       "995  https://blog.naver.com/gogoaec?Redirect=Log&lo...  \n",
       "996  https://blog.naver.com/bmw8888?Redirect=Log&lo...  \n",
       "997  https://blog.naver.com/zndkdvndkd?Redirect=Log...  \n",
       "998  https://blog.naver.com/bluekei9?Redirect=Log&l...  \n",
       "999  https://blog.naver.com/yansy?Redirect=Log&logN...  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crawling_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
